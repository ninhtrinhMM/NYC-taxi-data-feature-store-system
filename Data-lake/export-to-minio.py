import os
import json
import yaml
from utils.helpers import load_cfg
from minio.error import S3Error
from minio import Minio

# T·∫°o h√†m ƒë·ªçc file config.yaml
def load_cfg(config_file):
    """
    Load configuration from a YAML config file
    """
    cfg = None
    with open(config_file, "r") as f:
        try:
            cfg = yaml.safe_load(f)
        except yaml.YAMLError as exc:
            print(exc)

    return cfg

def main():

    #ƒê·ªçc file new_files_output.json ƒë·ªÉ l·∫•y ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c c·∫ßn upload
    with open("/opt/airflow/Project-Feature-Store/new_files_output.json", 'r') as f:
        new_files = json.load(f)
        
    # N·∫øu new_files r·ªóng
    if not new_files:
        print("------‚ö†Ô∏è Kh√¥ng c√≥ file m·ªõi ƒë·ªÉ upload!------")
        return
    # N·∫øu t√¨m th·∫•y 
    print(f"üÜï T√¨m th·∫•y {len(new_files)} file m·ªõi c·∫ßn x·ª≠ l√Ω:")

    #K·∫æT N·ªêI ƒê·∫æN MINIO 
    
    cfg = load_cfg("/opt/airflow/scripts/Data-lake/utils/config.yaml")
    datalake_cfg = cfg["datalake"]

    print(f"------üì¶ Chu·∫©n b·ªã c·∫•u h√¨nh c·ªßa {datalake_cfg['endpoint']}------") 

    minio_client = Minio(
        endpoint=datalake_cfg["endpoint"],
        access_key=datalake_cfg["access_key"],
        secret_key=datalake_cfg["secret_key"],
        secure=False,)

    print(f".... X√°c th·ª±c bucket t·∫°i {datalake_cfg['endpoint']}...")

    found = minio_client.bucket_exists(bucket_name=datalake_cfg["bucket_name"])
    if not found:
        minio_client.make_bucket(bucket_name=datalake_cfg["bucket_name"])
    else:
        print(f'Bucket {datalake_cfg["bucket_name"]} already exists, skip creating!')

    print(f".... ‚úÖ K·∫øt n·ªëi th√†nh c√¥ng ƒë·∫øn MinIO: {datalake_cfg['endpoint']}...")

    print(f"------üìÇ B·∫Øt ƒë·∫ßu upload l√™n MinIO------")
    success_file = 0
    failed_files = [] 

    for file in new_files:
        if not os.path.exists(file):
            print(f"  ‚ö†Ô∏è  File {os.path.basename(file)} kh√¥ng t·ªìn t·∫°i")
            continue
        try:
            minio_client.fput_object(
                bucket_name= datalake_cfg["bucket_name"],
                object_name= f"{datalake_cfg['folder_name']}/{os.path.basename(file)}" ,
                file_path=file,)
            
        except S3Error as e:
            print(f"  ‚ùå L·ªói upload: {e}")
            failed_files.append(os.path.basename(file))
        except Exception as e:
            print(f"  ‚ùå L·ªói kh√¥ng x√°c ƒë·ªãnh: {e}")
            failed_files.append(os.path.basename(file))

        success_file += 1
        print(f"-----Ho√†n t·∫•t upload file {os.path.basename(file)} l√™n MinIO, c√≤n l·∫°i {len(new_files) - success_file} file------")

    print(f"------‚úÖ Ho√†n t·∫•t upload {success_file}/{len(new_files)} l√™n MinIO!------")

    # ==== N·∫øu c√≥ file th·∫•t b·∫°i =======

    if not failed_files:
        print(" T·∫•t c·∫£ file ƒë√£ ƒë∆∞·ª£c upload th√†nh c√¥ng!") 

    print(f" Th·∫•t b·∫°i {len(failed_files)} file")
    print("---Danh s√°ch file th·∫•t b·∫°i:")
    for f in failed_files:
        print(f"  - {f}")

    
if __name__ == "__main__":
    main()